# -*- coding: utf-8 -*-
"""tinkering

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eDmoRYU_z5ea_wQFaRyK4OeJsDQ1iaJX
"""
import os
import mlrose
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import matplotlib.pyplot as plt
from mlxtend.plotting import plot_decision_regions

# from sklearn.datasets import load_iris
# from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
# import matplotlib
# matplotlib.use('agg')

np.random.seed(1)

"""# Machine Learning Weight Optimization Problems

The steps involved in solving a machine learning weight optimization problem with mlrose are typically:
1. Initialize a machine learning weight optimization problem object.
2. Find the optimal model weights for a given training dataset by calling the fit method of the object initialized
in step 1.
3. Predict the labels for a test dataset by calling the predict method of the object initialized in step 1.
"""


def create_decision_boundary(X, y, clf, data_name, clf_name):
    """Generates a decision boundary plot.
    Only suitable for two attributes and a class.

    Args:
        X (numpy.Array): Features.
        y (numpy.Array): Labels.
        clf (object): Target classifier.
        data_name (str): Name of data set being tested.
        clf_name (str): Type of algorithm.

    """

    # Plotting decision regions
    plot_decision_regions(np.array(X), np.array(y), clf=clf)

    # Adding axes annotations
    plt.grid(linestyle='dotted')
    plt.title("Decision Boundary with {} on {}".format(clf_name, data_name.capitalize()))

    # save iteration curve plot as PNG
    plotdir = 'plots'
    plot_tgt = '{}/{}'.format(plotdir, clf_name)
    plotpath = get_abspath('{}_DB.png'.format(data_name), plot_tgt)
    plt.savefig(plotpath)
    plt.close()


def get_abspath(filename, filepath):
    """Gets absolute path of specified file within the project directory. The
    filepath has to be a subdirectory within the main project directory.

    Args:
        filename (str): Name of specified file.
        filepath (str): Subdirectory of file.
    Returns:
        fullpath (str): Absolute filepath.

    """
    p = os.path.abspath(os.path.join(os.curdir, os.pardir))
    fullpath = os.path.join(p, filepath, filename)
    create_path_if_not_exists(('/'.join(fullpath.split('/')[:-1])))

    return fullpath


def create_path_if_not_exists(path):
    """Creates the given path if it does not already exist

    Args:
        path (str): a directory path, absolute or relative

    """
    if not os.path.exists(path):
        os.makedirs(path)


# filename = "./data/contraceptive.csv"
filename = "./data/banana.csv"
data = np.loadtxt(filename, delimiter=",", skiprows=1)

X = data[:, :-1]
y = data[:, -1]

"""## Data Normalization"""

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size=0.2,
                                                    random_state=3)

# Normalize feature data
# scaler = MinMaxScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)

X_train_scaled = X_train
X_test_scaled = X_test

# One hot encode target values
# one_hot = OneHotEncoder()
# y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()
# y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()

y_train_hot = y_train
y_test_hot = y_test

""" ## Neural Networks Gradient Descent """

# Initialize neural network object and fit object


algorithms = ['gradient_descent',
              # 'random_hill_climb',
              # 'simulated_annealing',
              # 'genetic_alg'
              ]

for a in algorithms:
    nn_model1 = mlrose.NeuralNetwork(hidden_nodes=[25, 25],
                                     activation='relu',
                                     algorithm=a,
                                     max_iters=10000,
                                     bias=True,
                                     is_classifier=True,
                                     learning_rate=0.01,
                                     # early_stopping=True,
                                     max_attempts=100,
                                     clip_max=3,
                                     )

    nn_model1.fit(X_train_scaled, y_train_hot)

    # Predict labels for train set and assess accuracy
    y_train_pred = nn_model1.predict(X_train_scaled)
    y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)

    print(a, "y_train_accuracy", y_train_accuracy)
    # 0.45

    # Predict labels for test set and assess accuracy
    y_test_pred = nn_model1.predict(X_test_scaled)
    y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)

    print(a, "y_test_accuracy", y_test_accuracy)
    # 0.533333333333

    create_decision_boundary(
        X=X_test,
        y=y_test.astype(np.integer),
        clf=nn_model1,
        data_name="banana",
        clf_name=a
    )

## Banana
# gradient_descent      y_train_accuracy            0.5504716981132075
# gradient_descent      y_test_accuracy             0.5566037735849056
# random_hill_climb     y_train_accuracy            0.5504716981132075
# random_hill_climb     y_test_accuracy             0.5566037735849056
# simulated_annealing   y_train_accuracy            0.5504716981132075
# simulated_annealing   y_test_accuracy             0.5566037735849056
# genetic_alg           y_train_accuracy            0.5504716981132075
# genetic_alg           y_test_accuracy             0.5566037735849056

## Contraceptives
# gradient_descent      y_train_accuracy            0.4244482173174873
# gradient_descent      y_test_accuracy             0.4067796610169492
# random_hill_climb     y_train_accuracy            0.3709677419354839
# random_hill_climb     y_test_accuracy             0.41694915254237286
# simulated_annealing   y_train_accuracy            0.30560271646859083
# simulated_annealing   y_test_accuracy             0.2542372881355932
# genetic_alg           y_train_accuracy            0.4202037351443124
# genetic_alg           y_test_accuracy             0.4576271186440678

mlrose.MaxKColor